services:
  db:
    image: postgres:16.4-alpine3.20
    # set shared memory limit when using docker-compose
    shm_size: 128mb
    environment:
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_TABLE_NAME}
    volumes:
      - b2b_db_data:/var/lib/postgresql/data
      - ./icons:/icons
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 5s
    networks:
      - b2b-network
      - logging
    restart: always

  backend:
    build:
      context: ..
      dockerfile: Deploy/Dockerfile
    ports:
      - "8082:8082"
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy
      notifications:
        condition: service_started
      loki:
        condition: service_started
    environment:
      POSTGRES_HOST: db
      DB_TABLE_NAME: ${DB_TABLE_NAME}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY}
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      STORAGE_HOST: http://minio:9000
      STORAGE_USER: ${STORAGE_USER}
      STORAGE_PASSWORD: ${STORAGE_PASSWORD}
      STORAGE_BUCKET_NAME: ${STORAGE_BUCKET_NAME}
      FRONTEND_HOST: https://b2bapp.algorithmity.com # This is a string that is used to redirect users to the frontend.
      EMAIL_SERVICE_URL: http://notifications:8085/api/email/send
      CRON_EVERY_MONDAY_AT_9: ${CRON_EVERY_MONDAY_AT_9}
      CRON_TUESDAY_TO_FRIDAY_AT_9: ${CRON_TUESDAY_TO_FRIDAY_AT_9}
      CRON_COMPANIES_NO_SKILLS_AND_NO_CUSTOM_FILTERS: ${CRON_COMPANIES_NO_SKILLS_AND_NO_CUSTOM_FILTERS}
      CRON_PROCESS_EXPIRING_PROJECTS: ${CRON_PROCESS_EXPIRING_PROJECTS}
      LOKI_HOST: loki
      LOG_LEVEL: ${LOG_LEVEL}
      ZIPKIN_HOST: zipkin
      DOMAIN_NAME: .algorithmity.com
      ZIPKIN_ENABLED: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 10
    networks:
      - b2b-network
      - logging
    restart: unless-stopped

  minio:
    image: 'bitnami/minio:latest'
    volumes:
      - b2b_minio_data:/bitnami/minio/data
    environment:
      MINIO_ROOT_USER: ${STORAGE_USER}
      MINIO_ROOT_PASSWORD: ${STORAGE_PASSWORD}
      MINIO_DEFAULT_BUCKETS: ${STORAGE_BUCKET_NAME},${LOKI_BUCKET_NAME}
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - b2b-network
      - logging
    restart: always

  mc:
    image: bitnami/minio-client:latest
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_SERVER_HOST: minio
      MINIO_SERVER_ACCESS_KEY: ${STORAGE_USER}
      MINIO_SERVER_SECRET_KEY: ${STORAGE_PASSWORD}
    entrypoint: >
      /bin/sh -c "
      sleep 10; 
      mc alias set myminio http://$${MINIO_SERVER_HOST}:9000 $${MINIO_SERVER_ACCESS_KEY} $${MINIO_SERVER_SECRET_KEY};
      mc anonymous set download myminio/company-assets;
      "
    networks:
      - b2b-network

  notifications:
    image: ludogoriesoft/b2b-notifications:v1
    environment:
      SPRING_MAIL_PASSWORD: ${SPRING_MAIL_PASSWORD}
      SPRING_MAIL_USERNAME: ${SPRING_MAIL_USERNAME}
    networks:
      - b2b-network
    restart: always

  loki:
    image: grafana/loki:3.2.1
    depends_on:
      minio:
        condition: service_healthy # Minio is used as a storage for loki
    environment:
      - LOKI_S3_USERNAME=${STORAGE_USER}
      - LOKI_S3_SECRET=${STORAGE_PASSWORD}
      - LOKI_S3_HOST=minio
      - LOKI_S3_PORT=9000
      - LOKI_S3_BUCKET_NAME=${LOKI_BUCKET_NAME}
    user: "root"
    volumes:
      - ./Logging/loki-config.yaml:/etc/loki/local-config.yaml:ro # Custom config
    command:
      - -config.expand-env=true  # Enable environment variable expansion
      - -config.file=/etc/loki/local-config.yaml
    networks:
      - logging
    restart: always

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3333:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PW}
      - DS_PROMETHEUS=prometheus
    volumes:
      - grafana-data:/var/lib/grafana
      - "./Logging/Grafana/postgresql.json:/var/lib/grafana/dashboards/postgresql.json"
      - "./Logging/Grafana/docker.json:/var/lib/grafana/dashboards/docker.json"
      - "./Logging/Grafana/host.json:/var/lib/grafana/dashboards/host.json"
      - "./Logging/Grafana/loki.json:/var/lib/grafana/dashboards/loki.json"
      - "./Logging/Grafana/zipkin.json:/var/lib/grafana/dashboards/zipkin.json"
      - "./Logging/Grafana/default.yaml:/etc/grafana/provisioning/dashboards/default.yaml"
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
        - name: Loki
          type: loki
          access: proxy
          orgId: 1
          url: http://loki:3100
          basicAuth: false
          isDefault: true
          version: 1
          editable: false
        - name: prometheus
          type: prometheus
          url: http://prometheus:9090
          access: proxy
          isDefault: false
        EOF
        /run.sh
    networks:
      - logging
    depends_on:
      - prometheus
      - loki
    restart: always

  cadvisor:
    container_name: cadvisor
    image: gcr.io/cadvisor/cadvisor:latest
    networks:
      - logging
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /etc/machine-id:/etc/machine-id:ro
      - /var/lib/dbus/machine-id:/var/lib/dbus/machine-id:ro
    privileged: true
    devices:
      - /dev/kmsg
    restart: always

  prometheus:
    container_name: prometheus
    image: prom/prometheus:latest
    networks:
      - logging
    volumes:
      - "./Logging/prometheus.yml:/etc/prometheus/prometheus.yml"
    privileged: true
    restart: always

  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter
    container_name: postgres_exporter
    environment:
      DATA_SOURCE_URI: db:5432/${DB_TABLE_NAME}?sslmode=disable
      DATA_SOURCE_USER: ${DB_USERNAME}
      DATA_SOURCE_PASS: ${DB_PASSWORD}
    networks:
      - logging
    depends_on:
      - db
    restart: always

  node-exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - '--path.rootfs=/host'
    networks:
      - logging
    pid: host
    restart: unless-stopped
    volumes:
      - '/:/host:ro,rslave'

  zipkin:
    image: ghcr.io/openzipkin/zipkin-slim:latest
    container_name: zipkin
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=elasticsearch:9200
      - ZIPKIN_METRICS_PROMETHEUS_ENABLED=true
    ports:
      - "9411:9411"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - logging
    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.16.1
    container_name: elasticsearch
    restart: unless-stopped
    ports:
      - "9200:9200"
    environment:
      discovery.type: single-node
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    volumes:
      - zipkin_elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: "curl -f http://localhost:9200 || exit 1"
    networks:
      - logging

networks:
  b2b-network:
    driver: bridge
  logging:
    driver: bridge
volumes:
  b2b_minio_data:
  b2b_db_data:
  grafana-data:
  zipkin_elasticsearch_data: